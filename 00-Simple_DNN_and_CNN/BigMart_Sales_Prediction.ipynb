{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4acb488",
   "metadata": {},
   "source": [
    "__Project:__ Simple DNN and CNN <br>\n",
    "__Sub-prj:__ DNN Regression with Keras <br>\n",
    "__Experm:__ Data Prep & Regression on Tabular Data (Big Mart Sales Pred) <br>\n",
    "__Devl by:__ Amir Hossini <br>\n",
    "__Dev Dat:__ Oct 9, 2021 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c93f4",
   "metadata": {},
   "source": [
    "![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c3d4a",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de8d8858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciKitLearn Version: 1.0\n",
      "Tensorflow Version: 2.5.0\n",
      "Number of available GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f'SciKitLearn Version: {sklearn.__version__}')\n",
    "print(f'Tensorflow Version: {tf.__version__}')\n",
    "print('Number of available GPUs: {}'.format(len(tf.config.list_physical_devices('GPU'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab1bd7",
   "metadata": {},
   "source": [
    "#### I/O Files & Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6870d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_train     = './datasets/big_mart_sales/train.csv'\n",
    "fl_test      = './datasets/big_mart_sales/test.csv'\n",
    "\n",
    "excl_list    = ['Item_Identifier']\n",
    "ordinal_list = ['Outlet_Location_Type']\n",
    "nominal_list = ['Item_Fat_Content','Item_Type','Outlet_Identifier','Outlet_Establishment_Year','Outlet_Size','Outlet_Type']\n",
    "\n",
    "ordinal_labels_dict = {\n",
    "    'Outlet_Location_Type':{'Tier 1': 0, 'Tier 2': 1, 'Tier 3': 2},\n",
    "}\n",
    "\n",
    "item_fat_content_map = {\n",
    "    'Low Fat':'LF', 'Regular':'Reg', 'low fat':'LF', 'LF':'LF', 'reg':'Reg'\n",
    "}\n",
    "\n",
    "target_var = ['Item_Outlet_Sales']\n",
    "\n",
    "val_split = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee7358",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13da7c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_ordinal(dataframe,columns,ordinal_labels_dict):\n",
    "    df = dataframe.copy()\n",
    "    for col in columns:\n",
    "        label_dict = ordinal_labels_dict[col]\n",
    "        df.loc[:,col] = df.loc[:,col].map(lambda x: label_dict[x])\n",
    "    return df\n",
    "    \n",
    "def prep_nominal(dataframe,columns):\n",
    "    df = dataframe.copy()\n",
    "    for col in columns:\n",
    "        tmp_df=pd.get_dummies(df[col],prefix=col)\n",
    "        tmp_df=tmp_df.iloc[: , :-1]\n",
    "        df.drop(columns=[col],inplace=True)\n",
    "        df=pd.concat([df,tmp_df],axis=1)\n",
    "    return df\n",
    "\n",
    "def prep_normalize(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df_scaled=pd.DataFrame(MinMaxScaler().fit_transform(df),columns=df.columns)\n",
    "    return df_scaled\n",
    "\n",
    "def split_data(dataframe,target_col,test_split_prop=0.2):\n",
    "    df = dataframe.copy()\n",
    "    X  = df.drop(columns=target_col)\n",
    "    y  = df[target_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_split_prop)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769edbc2",
   "metadata": {},
   "source": [
    "#### Read In & Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a282d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 8523\n",
      "Test Size: 5681\n",
      "\n",
      "Percentage of missing: Train\n",
      "Item_Identifier               0.000000\n",
      "Item_Weight                  17.165317\n",
      "Item_Fat_Content              0.000000\n",
      "Item_Visibility               0.000000\n",
      "Item_Type                     0.000000\n",
      "Item_MRP                      0.000000\n",
      "Outlet_Identifier             0.000000\n",
      "Outlet_Establishment_Year     0.000000\n",
      "Outlet_Size                  28.276428\n",
      "Outlet_Location_Type          0.000000\n",
      "Outlet_Type                   0.000000\n",
      "Item_Outlet_Sales             0.000000\n",
      "dtype: float64\n",
      "\n",
      "Percentage of missing: Test\n",
      "Item_Identifier               0.000000\n",
      "Item_Weight                  17.180074\n",
      "Item_Fat_Content              0.000000\n",
      "Item_Visibility               0.000000\n",
      "Item_Type                     0.000000\n",
      "Item_MRP                      0.000000\n",
      "Outlet_Identifier             0.000000\n",
      "Outlet_Establishment_Year     0.000000\n",
      "Outlet_Size                  28.269671\n",
      "Outlet_Location_Type          0.000000\n",
      "Outlet_Type                   0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(fl_train)\n",
    "test  = pd.read_csv(fl_test)\n",
    "\n",
    "print(f'Train Size: {len(train)}')\n",
    "print(f'Test Size: {len(test)}')\n",
    "print('\\nPercentage of missing: Train')\n",
    "print(train.isna().sum()/len(train)*100)\n",
    "\n",
    "print('\\nPercentage of missing: Test')\n",
    "print(test.isna().sum()/len(test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3b279",
   "metadata": {},
   "source": [
    "#### Missing data handling & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a3fcdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.loc[train['Item_Weight'].isna(),'Item_Weight'] = train['Item_Weight'].mean()\n",
    "test.loc[test['Item_Weight'].isna(),'Item_Weight'] = test['Item_Weight'].mean()\n",
    "\n",
    "train.loc[train['Outlet_Size'].isna(),'Outlet_Size'] = 'Unknown'\n",
    "test.loc[test['Outlet_Size'].isna(),'Outlet_Size'] = 'Unknown'\n",
    "\n",
    "train.loc[:,'Item_Fat_Content']=train.loc[:,'Item_Fat_Content'].map(lambda x: item_fat_content_map[x])\n",
    "test.loc[:,'Item_Fat_Content']=test.loc[:,'Item_Fat_Content'].map(lambda x: item_fat_content_map[x])\n",
    "\n",
    "train.drop(columns=['Item_Identifier'],inplace=True)\n",
    "test.drop(columns=['Item_Identifier'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737cf624",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb328cf6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train=(train.pipe(prep_ordinal,ordinal_list,ordinal_labels_dict)\n",
    "    .pipe(prep_nominal,nominal_list)\n",
    "    .pipe(prep_normalize)\n",
    ")\n",
    "\n",
    "test=(test.pipe(prep_ordinal,ordinal_list,ordinal_labels_dict)\n",
    "    .pipe(prep_nominal,nominal_list)\n",
    "    .pipe(prep_normalize)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40966a79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = split_data(train,target_var,val_split)\n",
    "n_features = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f360f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2.5]",
   "language": "python",
   "name": "conda-env-tf2.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
